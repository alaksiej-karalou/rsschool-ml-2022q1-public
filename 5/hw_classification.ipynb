{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{2C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "\n",
    "    def __init__(self, eta = 0.001, max_iter = 1000, C = 1.0, tol = 1e-5, random_state = 42, zero_init = False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = np.random.RandomState(seed = random_state)\n",
    "        self.zero_init = zero_init\n",
    "        self.loss = np.array([])\n",
    "        self.actual_iter_count = 0\n",
    "\n",
    "    def get_sigmoid(self, X, weights):\n",
    "        return 1 / (1 + np.exp(-X @ weights))\n",
    "\n",
    "    def get_loss(self, x, weights, y):\n",
    "        return np.mean(\n",
    "            np.log(1 + np.exp(-(x @ weights) * y))\n",
    "        ) + np.linalg.norm(weights) / (2 * self.C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])  # a constant feature is included to handle intercept\n",
    "        num_samples = X_ext.shape[0]\n",
    "        num_features = X_ext.shape[1]\n",
    "\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features)\n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low = -weight_threshold,\n",
    "                                                      high = weight_threshold,\n",
    "                                                      size = num_features)  # random weight initialization\n",
    "        #y = y.reshape(-1, 1)\n",
    "        #self.weights_ = self.weights_.reshape(1, -1)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.actual_iter_count = i + 1\n",
    "            delta = 0\n",
    "            for j in range(num_samples):\n",
    "                delta += y[j] * X_ext[j] * (1 - 1 / (1 + np.exp(-(self.weights_ @ X_ext[j] * y[j]))))\n",
    "            delta = delta / num_samples\n",
    "            delta = delta - self.weights_ / self.C\n",
    "            self.loss = np.append(self.loss,\n",
    "                                  [i,\n",
    "                                   self.get_loss(X_ext, self.weights_, y),\n",
    "                                   np.linalg.norm(self.eta * delta, ord = 2)])\n",
    "\n",
    "            if np.linalg.norm(delta) < self.tol:\n",
    "                break\n",
    "\n",
    "            self.weights_ += self.eta * delta\n",
    "\n",
    "        self.loss = self.loss.reshape(-1, 3)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else:\n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        prediction = np.array([])\n",
    "        for i in range(X.shape[0]):\n",
    "            prediction = np.append(prediction, 1 if self.predict_proba(X[i, :].reshape(1, -1)) > 0.5 else -1)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class = 10, return_X_y = True)\n",
    "\n",
    "_, axes = plt.subplots(nrows = 3, ncols = 7, figsize = (10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap = plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)\n",
    "y_train = (y_train % 2) * 2 - 1\n",
    "y_test = (y_test % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(360, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1437, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(360, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize = 'true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return metrics.accuracy_score(y_pred = clf.predict(X_train), y_true = y_train), metrics.accuracy_score(\n",
    "        y_pred = clf.predict(X_test), y_true = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter = 1, zero_init = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomLogisticRegression at 0x22ec7e23d30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([3.1000e-06, 0.0000e+00, 4.1800e-05, 5.4770e-04, 2.2130e-04,\n",
    "                                              4.8750e-04, 1.3577e-03, 5.9780e-04, 5.6400e-05, -7.0000e-07,\n",
    "                                              1.6910e-04, 2.5190e-04, -4.3700e-04, 3.6190e-04, 1.0049e-03,\n",
    "                                              4.2280e-04, 2.5700e-05, 3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "                                              -2.6200e-04, 8.7540e-04, 4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "                                              0.0000e+00, -2.2160e-04, -5.7130e-04, 9.8570e-04, 1.3507e-03,\n",
    "                                              5.0210e-04, -1.7050e-04, -1.0000e-06, 0.0000e+00, -6.7810e-04,\n",
    "                                              -1.0515e-03, -4.4500e-05, 3.7160e-04, 4.2100e-04, -8.1800e-05,\n",
    "                                              0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "                                              1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "                                              -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "                                              -3.9560e-04, -1.7700e-05, -3.0000e-07, 2.6800e-05, 6.3920e-04,\n",
    "                                              1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]),\n",
    "                   atol = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Data\\Python\\3.10.2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min(train_acc, test_acc) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss[:, 0], model.loss[:, 1])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.loss[:, 0], model.loss[:, 2])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('weight difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate\n",
       "0          1.000\n",
       "1          0.100\n",
       "2          0.010\n",
       "3          0.001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "logistic_rates = pd.DataFrame({\n",
    "    'learning_rate': 1 / 10 ** np.arange(4)}\n",
    ")\n",
    "logistic_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit_evaluate_metrics(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    return metrics.accuracy_score(y_pred = y_train_pred, y_true = y_train), metrics.accuracy_score(\n",
    "        y_pred = y_test_pred, y_true = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate_metric(y_test, y_test_pred):\n",
    "    return metrics.accuracy_score(y_pred = y_train_pred, y_true = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliaksei.karaliou\\AppData\\Local\\Temp\\ipykernel_10152\\2602925069.py:65: RuntimeWarning: overflow encountered in exp\n",
      "  delta += y[j] * X_ext[j] * (1 - 1 / (1 + np.exp(-(self.weights_ @ X_ext[j] * y[j]))))\n",
      "C:\\Users\\aliaksei.karaliou\\AppData\\Local\\Temp\\ipykernel_10152\\2602925069.py:36: RuntimeWarning: overflow encountered in exp\n",
      "  np.log(1 + np.exp(-(x @ weights) * y))\n"
     ]
    }
   ],
   "source": [
    "logistic_rates['model'] = logistic_rates.apply(\n",
    "    lambda row: CustomLogisticRegression(eta = row['learning_rate']).fit(X_train, y_train),\n",
    "    axis = 1)\n",
    "logistic_rates = logistic_rates.join(logistic_rates.apply(\n",
    "    lambda row: fit_evaluate_metrics(y_train, row['model'].predict(X_train), y_test, row['model'].predict(X_test)),\n",
    "    axis = 1,\n",
    "    result_type = 'expand'))\n",
    "logistic_rates.rename(columns = {0: \"train\", 1: \"test\"}, inplace = True)\n",
    "logistic_rates['iter'] = logistic_rates['model'].apply(lambda x: x.actual_iter_count)\n",
    "logistic_rates.drop('model', axis = 1, inplace = True)\n",
    "logistic_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fit_evaluate(CustomLogisticRegression(), X_train, y_train, X_test, y_test)\n",
    "fit_evaluate(CustomLogisticRegression(zero_init = True), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example there is no big sense between zero and random initialization, but random initialization can be useful in preventing preoverfitting, when initial weights already overfit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement weighted K-Neighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that training a KNN classifier is simply memorizing a training sample. \n",
    "\n",
    "The process of applying a classifier for one object is to find the distances from it to all objects in the training data, then select the k nearest objects (neighbors) and return the most common class among these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give the nearest neighbors weights in accordance with the distance of the object to them. In the simplest case (as in your assignment), you can set the weights inversely proportional to that distance. \n",
    "\n",
    "$$w_{i} = \\frac{1}{d_{i} + eps},$$\n",
    "\n",
    "where $d_{i}$ is the distance between object and i-th nearest neighbor and $eps$ is the small value to prevent division by zero.\n",
    "\n",
    "In case of 'uniform' weights, all k nearest neighbors are equivalent (have equal weight, for example $w_{i} = 1, \\forall i \\in(1,k)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the probability of classes, it is necessary to normalize the weights of each class, dividing them by the sum:\n",
    "\n",
    "$$p_{i} = \\frac{w_{i}}{\\sum_{j=1}^{c}w_{j}},$$\n",
    "\n",
    "where $p_i$ is probability of i-th class and $c$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits. By implementing this algorithm, you will be able to classify numbers not only into \"even\" or \"odd\", but into their real representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CustomKNeighborsClassifier:\n",
    "    _estimator_type = \"classifier\"\n",
    "\n",
    "    def __init__(self, n_neighbors = 5, weights = 'uniform', eps = 1e-9):\n",
    "        \"\"\"K-Nearest Neighbors classifier.\n",
    "\n",
    "        Args:\n",
    "            n_neighbors: int, default=5\n",
    "                Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "            weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "                Weight function used in prediction.  Possible values:\n",
    "                - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "                  are weighted equally.\n",
    "                - 'distance' : weight points by the inverse of their distance.\n",
    "                  in this case, closer neighbors of a query point will have a\n",
    "                  greater influence than neighbors which are further away.\n",
    "            eps : float, default=1e-5\n",
    "                Epsilon to prevent division by 0\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.eps = eps\n",
    "\n",
    "    def get_pairwise_distances(self, X, Y):\n",
    "        \"\"\"\n",
    "        Returnes matrix of the pairwise distances between the rows from both X and Y.\n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            Y: numpy array of shape (k_samples, n_features)\n",
    "        Returns:\n",
    "            P: numpy array of shape (n_samples, k_samples)\n",
    "                Matrix in which (i, j) value is the distance\n",
    "                between i'th row from the X and j'th row from the Y.\n",
    "        \"\"\"\n",
    "        result = np.array([])\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(Y.shape[0]):\n",
    "                result = np.append(result, np.sqrt((X[i][0] - Y[j][0]) ** 2 + (X[i][1] - Y[j][1]) ** 2))\n",
    "        return result.reshape(X.shape[0], Y.shape[0])\n",
    "\n",
    "    def get_class_weights(self, y, weights):\n",
    "        \"\"\"\n",
    "        Returns a vector with sum of weights for each class \n",
    "        Args:\n",
    "            y: numpy array of shape (n_samles,)\n",
    "            weights: numpy array of shape (n_samples,)\n",
    "                The weights of the corresponding points of y.\n",
    "        Returns:\n",
    "            p: numpy array of shape (n_classes)\n",
    "                Array where the value at the i-th position \n",
    "                corresponds to the weight of the i-th class.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame({\n",
    "            'y': y,\n",
    "            'weights': weights\n",
    "        })\n",
    "        res = df.groupby('y')['weights'].sum()\n",
    "\n",
    "        arr = np.array([])\n",
    "        for i in self.classes_:\n",
    "            arr = np.append(arr, res.loc[i])\n",
    "\n",
    "        return arr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.points = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples, n_classes)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'points'):\n",
    "            P = self.get_pairwise_distances(X, self.points)\n",
    "\n",
    "            weights_of_points = np.ones(P.shape)\n",
    "            if self.weights == 'distance':\n",
    "                weights_of_points = 1 / P\n",
    "\n",
    "            display(pd.DataFrame(P).shape)\n",
    "\n",
    "            # <your code>\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise NotFittedError(\"CustomKNeighborsClassifier instance is not fitted yet\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomKNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.get_pairwise_distances(np.array([[0, 1], [1, 1]]),\n",
    "                                                np.array([[0.5, 0.5], [1, 0]])),\n",
    "                   np.array([[0.70710678, 1.41421356],\n",
    "                             [0.70710678, 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_ = ['one', 'two', 'three']\n",
    "assert np.allclose(model.get_class_weights(np.array(['one', 'one', 'three', 'two']), np.array([1, 1, 0, 4])),\n",
    "                   np.array([2, 4, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = datasets.load_digits(n_class = 10, return_X_y = True)\n",
    "#\n",
    "#_, axes = plt.subplots(nrows = 3, ncols = 7, figsize = (10, 5))\n",
    "#for ax, image, label in zip(axes.flatten(), X, y):\n",
    "#    ax.set_axis_off()\n",
    "#    ax.imshow(image.reshape((8, 8)), cmap = plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "#    ax.set_title(label)\n",
    "#\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train)\n",
    "#knn.fit(X_train, list(map(str, y_train)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert np.allclose(model.predict_proba(X_test), knn.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert train_acc == 1\n",
    "#assert test_acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Take a look at the confusion matrix and tell what numbers the model confuses and why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different n_neighbors parameters and compare the output probabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare both 'uniform' and 'distance' weights and share your thoughts in what situations which parameter can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest another distance measurement function that could improve the quality of the classification for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest different task and distance function that you think would be suitable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Synthetic Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/tabular-playground-series-apr-2021/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_column(df: pd.DataFrame, sumColumn, calculateColumn):\n",
    "    return df.groupby(sumColumn)[calculateColumn].apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(data.groupby('Sex').size())\n",
    "display(data.groupby('Sex').size() / data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there were total 43886 women (43.9%) and 56114 men (56.1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_sex_data = data.groupby(['Sex', 'Survived']).size().reset_index(name = 'Count')\n",
    "survived_sex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"Sex\", y = \"Count\", hue = \"Survived\", data = survived_sex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_sex_data['Percentage'] = percentage_column(survived_sex_data, 'Sex', 'Count')\n",
    "survived_sex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived_sex_plot = sns.barplot(x = \"Sex\", y = \"Percentage\",\n",
    "                                data = survived_sex_data[survived_sex_data['Survived'] == 1])\n",
    "survived_sex_plot.bar_label(survived_sex_plot.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 71.15 of all women survived and ony 20.58% of all men"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Survived'] == 1]['Age'].agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that mean age for survived people is 40.5 years old, and median is 43 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Survived'] == 0]['Age'].agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that mean age for survived people is 36.7 years old, and median is 36 years old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let build a plot of survival depending on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = 3\n",
    "survived_age_grouped_data = data.groupby(\n",
    "    [pd.cut(data['Age'], np.arange(90 / age_group) * age_group), 'Survived']).size().rename(\n",
    "    'Count').reset_index()\n",
    "\n",
    "survived_age_grouped_data['Percentage'] = percentage_column(survived_age_grouped_data, 'Age', 'Count')\n",
    "survived_age_grouped_data = survived_age_grouped_data[\n",
    "    (survived_age_grouped_data['Survived'] == 1) & (survived_age_grouped_data['Percentage'].notna())]\n",
    "survived_age_grouped_data['Age'] = survived_age_grouped_data['Age'].apply(\n",
    "    lambda col: pd.Categorical(col).codes * age_group)\n",
    "survived_age_grouped_data['Percentage'] = survived_age_grouped_data['Percentage'].apply(lambda x: int(x))\n",
    "\n",
    "survived_age_plot = sns.barplot(x = survived_age_grouped_data['Age'], y = survived_age_grouped_data['Percentage'])\n",
    "survived_age_plot.bar_label(survived_age_plot.containers[0])\n",
    "plt.title('Survival depending on age')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that children and old men has better chance for survival. The worse survivors are yound age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passenger class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_pclass_data = data.groupby(['Pclass', 'Survived']).size().reset_index(name = 'Count')\n",
    "survived_pclass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"Pclass\", y = \"Count\", hue = \"Survived\", data = survived_pclass_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that better class leads to better surviving rate. Let's analyze it more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_pclass_data['Percentage'] = percentage_column(survived_pclass_data, 'Pclass', 'Count')\n",
    "survived_pclass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_pclass_plot = sns.barplot(x = \"Pclass\", y = \"Percentage\",\n",
    "                                   data = survived_pclass_data[survived_pclass_data['Survived'] == 1])\n",
    "survived_pclass_plot.bar_label(survived_pclass_plot.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that among 1st class 58% people survived, 52.5% among 2nd class and only 24.7 among 3rd class. **1st class is the safest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_embarked_data = data.groupby(['Embarked', 'Survived']).size().reset_index(name = 'Count')\n",
    "survived_embarked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"Embarked\", y = \"Count\", hue = \"Survived\", data = survived_embarked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that among people from Southampton embarking port much more deceased people, among Cherbourg embarking port much more survivors people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survived_embarked_data['Percentage'] = percentage_column(survived_embarked_data, 'Embarked', 'Count')\n",
    "survived_embarked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_embarked_plot = sns.barplot(x = \"Embarked\", y = \"Percentage\",\n",
    "                                     data = survived_embarked_data[survived_embarked_data['Survived'] == 1])\n",
    "survived_embarked_plot.bar_label(survived_embarked_plot.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that from `Cherbourg` 75.1% people survived and from `Southampton` only 31.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(PATH, 'titanic', 'test.csv'))\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let determine surving rate among people with missing age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_nan_data = data[data['Age'].isna()].groupby('Survived')['Name'].count()\n",
    "age_nan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_age_nan = age_nan_data[1] / age_nan_data.sum()\n",
    "survived_age_nan * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that 41% of such person was survived. If we look at our age distribution graph, similar surving has people from 39 to 45 age. Let choose 41 years old and fill this missing value by it to not to change correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].fillna(41)\n",
    "data_test['Age'] = data_test['Age'].fillna(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to analyze ticket field and extract number from it. If absense - let return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'constant', fill_value = 'no-ticket', add_indicator = True)\n",
    "imputer_df = pd.DataFrame(imputer.fit_transform(pd.DataFrame(data['Ticket'])))\n",
    "\n",
    "data['Ticket'] = pd.Series(imputer_df[0])\n",
    "data['Ticket_Missing'] = pd.Series(imputer_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_test = SimpleImputer(strategy = 'constant', fill_value = 'no-ticket', add_indicator = True)\n",
    "imputer_df_test = pd.DataFrame(imputer_test.fit_transform(pd.DataFrame(data_test['Ticket'])))\n",
    "data_test['Ticket'] = imputer_df_test[0]\n",
    "data_test['Ticket_Missing'] = imputer_df_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile('\\d+')\n",
    "data['Ticket'] = data['Ticket'].fillna('none')\n",
    "data['Ticket_Number'] = data['Ticket'].apply(lambda x: regex.findall(x)[0] if regex.findall(x) else 0)\n",
    "data.drop('Ticket', axis = 1, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Ticket'] = data_test['Ticket'].fillna('none')\n",
    "data_test['Ticket_Number'] = data_test['Ticket'].apply(lambda x: regex.findall(x)[0] if regex.findall(x) else 0)\n",
    "data_test.drop('Ticket', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare is skipped very rare, so, let fill it with mean value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'] = data['Fare'].fillna(data['Fare'].mean())\n",
    "data_test['Fare'] = data_test['Fare'].fillna(data['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at `Embarked` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 'Embarked' is categorial feature. So, let fill missing data with `N` category, which not exists yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'] = data['Embarked'].fillna('N')\n",
    "data['Embarked'].value_counts()\n",
    "data_test['Embarked'] = data_test['Embarked'].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at cabin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that values are specified as pattern: letter and 4-5 digits. Let verify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data['Cabin'].dropna().unique()).str.match('^\\w\\d{4,5}$').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that we are right. Let split this column, to letter and number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let use imputer to fill empty cabin number values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'constant', fill_value = 'N0000', add_indicator = True)\n",
    "imputer_df = pd.DataFrame(imputer.fit_transform(pd.DataFrame(data['Cabin'])))\n",
    "data['Cabin'] = pd.Series(imputer_df[0])\n",
    "data['Cabin_Missing'] = pd.Series(imputer_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'constant', fill_value = 'N0000', add_indicator = True)\n",
    "imputer_df_test = pd.DataFrame(imputer.fit_transform(pd.DataFrame(data_test['Cabin'])))\n",
    "data_test['Cabin'] = pd.Series(imputer_df_test[0])\n",
    "data_test['Cabin_Missing'] = pd.Series(imputer_df_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Cabin_Missing'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Cabin_Number'] = data['Cabin'].str.replace('^\\w', '')\n",
    "data.drop('Cabin', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Cabin_Number'] = data_test['Cabin'].str.replace('^\\w', '')\n",
    "data_test.drop('Cabin', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum() / data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get rid of all missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let modify our columns to float view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop('Name', axis = 1, inplace = True)\n",
    "data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "\n",
    "data = data.join(pd.get_dummies(data['Embarked']))\n",
    "data.drop('Embarked', axis = 1, inplace = True)\n",
    "\n",
    "data['Ticket_Missing'] = data['Ticket_Missing'].astype(int)\n",
    "data['Cabin_Missing'] = data['Cabin_Missing'].astype(int)\n",
    "data.set_index('PassengerId', inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop('Name', axis = 1, inplace = True)\n",
    "data_test['Sex'] = data_test['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "\n",
    "data_test = data_test.join(pd.get_dummies(data_test['Embarked']))\n",
    "data_test.drop('Embarked', axis = 1, inplace = True)\n",
    "\n",
    "data_test['Ticket_Missing'] = data_test['Ticket_Missing'].astype(int)\n",
    "data_test['Cabin_Missing'] = data_test['Cabin_Missing'].astype(int)\n",
    "data_test.set_index('PassengerId', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('Survived')\n",
    "x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model):\n",
    "    return Pipeline([\n",
    "        ('sca', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_result(model, x_test, y_test):\n",
    "    return pd.DataFrame({\n",
    "        'true': y_test,\n",
    "        'predict': model.predict(x_test)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = make_model(LogisticRegression(max_iter = 1000, random_state = 42, n_jobs = -1))\n",
    "log_model.fit(x_train, y_train)\n",
    "\n",
    "fit_evaluate_metrics(y_train = y_train,\n",
    "                     y_train_pred = log_model.predict(x_train),\n",
    "                     y_test = y_test,\n",
    "                     y_test_pred = log_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try to balance weights of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_count = y_train.shape[0]\n",
    "weight_0 = y_train.value_counts()[0] / total_count\n",
    "weight_1 = y_train.value_counts()[1] / total_count\n",
    "\n",
    "log_balanced_model = make_model(LogisticRegression(max_iter = 5000,\n",
    "                                                   random_state = 42,\n",
    "                                                   class_weight = {0: weight_0, 1: weight_1},\n",
    "                                                   n_jobs = -1))\n",
    "\n",
    "log_balanced_model.fit(x_train, y_train)\n",
    "\n",
    "fit_evaluate_metrics(y_train = y_train,\n",
    "                     y_train_pred = log_balanced_model.predict(x_train),\n",
    "                     y_test = y_test,\n",
    "                     y_test_pred = log_balanced_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try to use polinomial features with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def make_polin_model(model, degree, num_features):\n",
    "    num_transformer = Pipeline(steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree))\n",
    "    ])\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('numeric_transformer', num_transformer, num_features),\n",
    "        ])\n",
    "\n",
    "    return Pipeline([\n",
    "        ('transformer', transformer),\n",
    "        ('sca', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol(x, x_train, y_train, num_features):\n",
    "    display(x)\n",
    "    return make_polin_model(LogisticRegression(n_jobs = -1), x, num_features).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "num_features = ['Age', 'Fare']\n",
    "polin_log_model = pd.DataFrame(\n",
    "    {\n",
    "        'degree': np.arange(1, 5)\n",
    "    })\n",
    "display(polin_log_model)\n",
    "polin_log_model['model'] = polin_log_model['degree'].apply(\n",
    "    lambda n: pol(n, x_train, y_train, num_features))\n",
    "\n",
    "polin_log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial features show very low result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(polin_log_model['model'].apply(\n",
    "    lambda model: fit_evaluate_metrics(y_train = y_train, y_train_pred = model.predict(x_train),\n",
    "                                       y_test = y_test, y_test_pred = model.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "def knn_to_value(df):\n",
    "    return pd.Series(df).apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "\n",
    "knn_model = make_model(KNeighborsRegressor(n_jobs = -1))\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "fit_evaluate_metrics(y_train = y_train,\n",
    "                     y_train_pred = knn_to_value(knn_model.predict(x_train)),\n",
    "                     y_test = y_test,\n",
    "                     y_test_pred = knn_to_value(knn_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "def knn_to_value(df):\n",
    "    return pd.Series(df).apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "\n",
    "knn_model = make_model(KNeighborsRegressor(weights = 'distance', n_jobs = -1))\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "fit_evaluate_metrics(y_train = y_train,\n",
    "                     y_train_pred = knn_to_value(knn_model.predict(x_train)),\n",
    "                     y_test = y_test,\n",
    "                     y_test_pred = knn_to_value(knn_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use different k for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_models = pd.DataFrame(\n",
    "    {\n",
    "        'neighbors': np.arange(1, 11, 1)\n",
    "    })\n",
    "knn_models['model'] = knn_models['neighbors'].apply(\n",
    "    lambda n: make_model(KNeighborsRegressor(n_neighbors = n, n_jobs = -1)).fit(x_train, y_train))\n",
    "knn_models['model_dist'] = knn_models['neighbors'].apply(\n",
    "    lambda n: make_model(KNeighborsRegressor(n_neighbors = n, weights = 'distance', n_jobs = -1)).fit(x_train, y_train))\n",
    "knn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(knn_models['model'].apply(\n",
    "    lambda model: fit_evaluate_metrics(y_train = y_train, y_train_pred = knn_to_value(model.predict(x_train)),\n",
    "                                       y_test = y_test, y_test_pred = knn_to_value(model.predict(x_test)))))\n",
    "display(knn_models['model_dist'].apply(\n",
    "    lambda model: fit_evaluate_metrics(y_train = y_train, y_train_pred = knn_to_value(model.predict(x_train)),\n",
    "                                       y_test = y_test, y_test_pred = knn_to_value(model.predict(x_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_models['model'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_pred = y_train_pred, y_true = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let unite the best 2 metrics for Logistic Regression and KNN and vote according coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take:\n",
    "* LogisticRegression(max_iter = 1000, random_state = 42, n_jobs = -1) - test_score = 0.76995\n",
    "* LogisticRegression(max_iter = 1000, random_state = 42, class_weight = {0: weight_0, 1: weight_1}, n_jobs = -1) - test_score = 0.7621\n",
    "* KNeighborsRegressor(n_neighbors = 6, n_jobs = -1) - test_score = 0.75236\n",
    "* LogisticRegression(max_iter = 5000, random_state = 42, class_weight = {0: weight_0, 1: weight_1}, n_jobs = -1) - test_score = 0.7621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame({\n",
    "    'model': [log_model, log_balanced_model, knn_models['model'][9], knn_models['model_dist'][9]],\n",
    "    'test_score': [0.76995, 0.7621, 0.75236, 0.7]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_preds=model_df.apply(lambda row: knn_to_value(row['model'].predict(x_test)) * row[\"test_score\"], axis = 1, result_type='expand')\n",
    "model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let calculate enough coefficient to be recognized as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_score=model_df['test_score'].sum()/2\n",
    "pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final_preds=(model_preds.sum()>pos_score).astype('int')\n",
    "model_final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_pred = model_final_preds, y_true = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see score 77%. Let execute it on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.apply(lambda row: knn_to_value(row['model'].predict(data_test)) * row[\"test_score\"], axis = 1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model, load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "\n",
    "**Note**. X points will depend on your kaggle public leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.79 \\leq score < 0.80,$$\n",
    "$$ f(score) = 2.5, \\ \\ 0.80 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 4.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
